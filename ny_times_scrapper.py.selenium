from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
# from selenium.webdriver.chrome.service import Service
# from webdriver_manager.chrome import ChromeDriverManager
# from selenium.webdriver.common.window import WindowTypes

from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.window import WindowTypes

from convert_data import ConvertData
import time

class NYTScrapper:
    def __init__(self):
        self.recipe = {}
        self.convert_data = ConvertData()
        # from selenium import webdriver
        # from selenium.webdriver.chrome.service import Service
        # from webdriver_manager.chrome import ChromeDriverManager
        # self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
        options = webdriver.ChromeOptions()
        # options.add_argument(r"--user-data-dir=/Users/davidrosenberg/Library/Application Support/Google/Chrome/Default")
        # options.add_argument(r"--profile-directory=Default")
        options.add_experimental_option("detach", True)
        # self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        # self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        # self.driver = webdriver.Chrome(service=Service("/Applications/Google Chrome.app"))
        self.driver = webdriver.Chrome(options=options)
        self.driver.get('https://cooking.nytimes.com')
        self.first_tab = self.driver.current_window_handle
        time.sleep(30)


    def scrapper(self, url):

        # original_window_handle = self.driver.current_window_handle
        self.driver.switch_to.window(WindowTypes.TAB)
        self.driver.get(url)

        #===== Title ========
        title = self.driver.find_element(By.CSS_SELECTOR, '[class*="pantry--title"]').text
        print(title)
        author =  self.driver.find_element(By.XPATH, '//*[@id="__next"]/div/main/div/div[1]/div[1]/div[1]/header/div/h2/a').text
        print(author)

        #===== Intro =======
        intro = self.driver.find_element(By.CSS_SELECTOR, '[class*="topnote_topnoteParagraphs"]').find_elements(By.TAG_NAME, 'p')
        intro_text = ""
        for paragraph in intro:
            intro_text += paragraph.text + '\n'
        print(intro_text)

        #===== Ingredients =====
        ingredient_block = self.driver.find_element(By.CSS_SELECTOR, '[class*="recipebody_ingredients-block"]')
        print(ingredient_block.text)
        # titles = ingredient_block.find_elements(By.TAG_NAME, 'h3')
        # ingredient_list = []
        # if titles:
        #     ingredient_ul = ingredient_block.find_elements(By.TAG_NAME, 'ul')
        #     group_titles = []
        #     for index in range(0, len(titles)):
        #         group_titles.append(titles[index].text)
        #         ingredient_group = ingredient_ul[index].find_elements(By.TAG_NAME, 'li')
        #         group_ingredients = []
        #         for ingredient in ingredient_group:
        #             group_ingredients.append(
        #                 ingredient.find_element(By.CSS_SELECTOR, 'span:nth-of-type(1)').text + " " +
        #                 ingredient.find_element(By.CSS_SELECTOR, 'span:nth-of-type(2)').text or ""
        #             )
        #         ingredient_list.append({
        #             "Group": titles[index].text,
        #             "Ingredients": group_ingredients,
        #         })
        # else:
        #     ingredients = ingredient_block.find_elements(By.TAG_NAME, 'li')
        #     for ingredient in ingredients:
        #         ingredient_list.append(
        #             ingredient.find_element(By.CSS_SELECTOR, 'span[class*="ingredient_quantity"]').text + " " +
        #             ingredient.find_element(By.CSS_SELECTOR, 'span:nth-of-type(2)').text
        #         )
        # print(ingredient_list)